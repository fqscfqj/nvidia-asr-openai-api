# -*- coding: utf-8 -*-
"""
FastAPI ä¸»åº”ç”¨æ¨¡å—

æä¾› OpenAI Whisper å…¼å®¹çš„ REST API æ¥å£:
- POST /v1/audio/transcriptions - éŸ³é¢‘è½¬å½•
- GET /health - å¥åº·æ£€æŸ¥
- GET /status - æ¨¡å‹çŠ¶æ€
- POST /model/load - é¢„åŠ è½½æ¨¡å‹
- POST /model/unload - å¸è½½æ¨¡å‹
"""

import os
import sys
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Query
from fastapi.responses import PlainTextResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from loguru import logger

from .model_manager import get_model_manager, shutdown_model_manager
from .engine import get_transcription_engine


# ============================================================================
# æ—¥å¿—é…ç½®
# ============================================================================

def setup_logging():
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿ
    
    ä½¿ç”¨ loguru åº“å®ç°ç»“æ„åŒ–æ—¥å¿—, æ”¯æŒ:
    - æ§åˆ¶å°å½©è‰²è¾“å‡º
    - æ–‡ä»¶æ—¥å¿—è½®è½¬
    - æ—¥å¿—çº§åˆ«é…ç½®
    """
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()
    
    # æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨
    logger.add(
        sys.stdout,
        level=log_level,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
               "<level>{level: <8}</level> | "
               "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | "
               "<level>{message}</level>",
        colorize=True,
    )
    
    logger.info(f"æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–, çº§åˆ«: {log_level}")


# ============================================================================
# åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
    
    å¯åŠ¨æ—¶:
    - åˆå§‹åŒ–æ—¥å¿—
    - åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨ (ä½†ä¸åŠ è½½æ¨¡å‹, å®ç°æ‡’åŠ è½½)
    
    å…³é—­æ—¶:
    - å¸è½½æ¨¡å‹
    - é‡Šæ”¾ GPU èµ„æº
    """
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    setup_logging()
    logger.info("=== Canary ASR API æœåŠ¡å¯åŠ¨ ===")
    logger.info(f"æ¨¡å‹è·¯å¾„: {os.getenv('MODEL_PATH', '/data/model')}")
    logger.info(f"è¶…æ—¶æ—¶é—´: {os.getenv('MODEL_TIMEOUT_SEC', '300')}ç§’")
    logger.info(f"FP16 æ¨¡å¼: {os.getenv('USE_FP16', 'true')}")
    
    # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨ (ä»…åˆ›å»ºå®ä¾‹, ä¸åŠ è½½æ¨¡å‹)
    _ = get_model_manager()
    logger.info("æ¨¡å‹ç®¡ç†å™¨å·²å°±ç»ª (æ‡’åŠ è½½æ¨¡å¼, é¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½æ¨¡å‹)")
    
    yield
    
    # å…³é—­æ—¶æ‰§è¡Œ
    logger.info("=== æ­£åœ¨å…³é—­ API æœåŠ¡ ===")
    shutdown_model_manager()
    logger.info("API æœåŠ¡å·²å…³é—­")


# ============================================================================
# FastAPI åº”ç”¨å®ä¾‹
# ============================================================================

app = FastAPI(
    title="Canary ASR API",
    description="""
## NVIDIA Canary-1B-v2 è¯­éŸ³è¯†åˆ« API

å…¼å®¹ OpenAI Whisper API çš„è¯­éŸ³è½¬å½•æœåŠ¡, åŸºäº NVIDIA Canary-1B-v2 æ¨¡å‹ã€‚

### ç‰¹æ€§
- ğŸš€ **æ‡’åŠ è½½**: é¦–æ¬¡è¯·æ±‚æ—¶æ‰åŠ è½½æ¨¡å‹, èŠ‚çœèµ„æº
- â±ï¸ **è‡ªåŠ¨å¸è½½**: é—²ç½®è¶…æ—¶åè‡ªåŠ¨é‡Šæ”¾ GPU æ˜¾å­˜
- ğŸ¯ **é«˜ç²¾åº¦**: æ”¯æŒ 25 ç§æ¬§æ´²è¯­è¨€çš„è½¬å½•å’Œç¿»è¯‘
- ğŸ“ **å¤šæ ¼å¼**: æ”¯æŒ text/json/srt/vtt/verbose_json è¾“å‡ºæ ¼å¼

### æ”¯æŒçš„è¯­è¨€
en, de, fr, es, it, pt, nl, pl, ru, uk, cs, sk, bg, hr, da, fi, el, hu, ro, sv, et, lv, lt, sl, mt
    """,
    version="1.0.0",
    lifespan=lifespan,
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

class TranscriptionResponse(BaseModel):
    """è½¬å½•å“åº”æ¨¡å‹ (JSON æ ¼å¼)"""
    text: str
    language: Optional[str] = None
    duration: Optional[float] = None


class VerboseTranscriptionResponse(BaseModel):
    """è¯¦ç»†è½¬å½•å“åº”æ¨¡å‹ (verbose_json æ ¼å¼)"""
    task: str = "transcribe"
    text: str
    language: Optional[str] = None
    duration: Optional[float] = None
    segments: list = []
    words: Optional[list] = None


class ModelStatusResponse(BaseModel):
    """æ¨¡å‹çŠ¶æ€å“åº”"""
    model_loaded: bool
    model_name: str
    model_path: str
    usage_count: int
    idle_seconds: Optional[float] = None
    timeout_seconds: int
    use_fp16: bool
    gpu_available: bool
    gpu_name: Optional[str] = None
    gpu_memory_allocated_mb: Optional[float] = None
    gpu_memory_reserved_mb: Optional[float] = None


class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”"""
    status: str
    message: str


class OperationResponse(BaseModel):
    """æ“ä½œå“åº”"""
    success: bool
    message: str


# ============================================================================
# API è·¯ç”±
# ============================================================================

@app.get("/", response_class=PlainTextResponse)
async def root():
    """
    æ ¹è·¯ç”± - è¿”å›æœåŠ¡ä¿¡æ¯
    """
    return "Canary ASR API - å…¼å®¹ OpenAI Whisper API çš„è¯­éŸ³è¯†åˆ«æœåŠ¡"


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """
    å¥åº·æ£€æŸ¥ç«¯ç‚¹
    
    ç”¨äº Docker å¥åº·æ£€æŸ¥å’Œè´Ÿè½½å‡è¡¡å™¨æ¢æµ‹
    """
    return HealthResponse(
        status="healthy",
        message="æœåŠ¡è¿è¡Œæ­£å¸¸"
    )


@app.get("/status", response_model=ModelStatusResponse)
async def get_status():
    """
    è·å–æ¨¡å‹çŠ¶æ€
    
    è¿”å›æ¨¡å‹åŠ è½½çŠ¶æ€ã€GPU ä½¿ç”¨æƒ…å†µç­‰ä¿¡æ¯
    """
    manager = get_model_manager()
    status = manager.get_status()
    return ModelStatusResponse(**status)


@app.post("/model/load", response_model=OperationResponse)
async def load_model():
    """
    é¢„åŠ è½½æ¨¡å‹
    
    æ‰‹åŠ¨è§¦å‘æ¨¡å‹åŠ è½½, ç”¨äºé¢„çƒ­æœåŠ¡
    """
    try:
        manager = get_model_manager()
        success = manager.force_load()
        
        if success:
            return OperationResponse(
                success=True,
                message="æ¨¡å‹åŠ è½½æˆåŠŸ"
            )
        else:
            return OperationResponse(
                success=False,
                message="æ¨¡å‹åŠ è½½å¤±è´¥"
            )
    except Exception as e:
        logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")


@app.post("/model/unload", response_model=OperationResponse)
async def unload_model():
    """
    å¸è½½æ¨¡å‹
    
    æ‰‹åŠ¨é‡Šæ”¾ GPU æ˜¾å­˜
    """
    try:
        manager = get_model_manager()
        success = manager.force_unload()
        
        if success:
            return OperationResponse(
                success=True,
                message="æ¨¡å‹å·²å¸è½½, æ˜¾å­˜å·²é‡Šæ”¾"
            )
        else:
            return OperationResponse(
                success=False,
                message="æ— æ³•å¸è½½æ¨¡å‹ (å¯èƒ½æœ‰è¯·æ±‚æ­£åœ¨å¤„ç†)"
            )
    except Exception as e:
        logger.error(f"å¸è½½æ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¸è½½æ¨¡å‹å¤±è´¥: {e}")


@app.post("/v1/audio/transcriptions")
async def create_transcription(
    file: UploadFile = File(..., description="è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶"),
    model: str = Form(default="canary-1b-v2", description="æ¨¡å‹åç§° (å…¼å®¹å‚æ•°, å®é™…ä½¿ç”¨ Canary)"),
    language: Optional[str] = Form(default=None, description="éŸ³é¢‘è¯­è¨€ä»£ç , å¦‚ 'en', 'zh'"),
    response_format: str = Form(default="json", description="å“åº”æ ¼å¼: text, json, srt, vtt, verbose_json"),
    temperature: Optional[float] = Form(default=None, description="é‡‡æ ·æ¸©åº¦ (å…¼å®¹å‚æ•°, æš‚ä¸ä½¿ç”¨)"),
    timestamp_granularities: Optional[str] = Form(default=None, description="æ—¶é—´æˆ³ç²’åº¦ (å…¼å®¹å‚æ•°)"),
):
    """
    éŸ³é¢‘è½¬å½• API
    
    å…¼å®¹ OpenAI Whisper API çš„ /v1/audio/transcriptions ç«¯ç‚¹
    
    ## è¯·æ±‚å‚æ•°
    
    - **file**: éŸ³é¢‘æ–‡ä»¶ (æ”¯æŒ wav, flac, mp3, m4a ç­‰æ ¼å¼)
    - **model**: æ¨¡å‹åç§° (å…¼å®¹å‚æ•°, å®é™…ä½¿ç”¨ Canary-1B-v2)
    - **language**: éŸ³é¢‘è¯­è¨€ä»£ç , å¦‚ 'en', 'de', 'fr' ç­‰
    - **response_format**: å“åº”æ ¼å¼
        - `text`: çº¯æ–‡æœ¬
        - `json`: JSON æ ¼å¼ (é»˜è®¤)
        - `srt`: SRT å­—å¹•æ ¼å¼
        - `vtt`: WebVTT å­—å¹•æ ¼å¼
        - `verbose_json`: è¯¦ç»† JSON (åŒ…å«æ—¶é—´æˆ³)
    
    ## å“åº”
    
    æ ¹æ® response_format è¿”å›ä¸åŒæ ¼å¼çš„è½¬å½•ç»“æœ
    
    ## ç¤ºä¾‹
    
    ```python
    import requests
    
    url = "http://localhost:8000/v1/audio/transcriptions"
    files = {"file": open("audio.wav", "rb")}
    data = {"language": "en", "response_format": "json"}
    
    response = requests.post(url, files=files, data=data)
    print(response.json())
    ```
    """
    # éªŒè¯å“åº”æ ¼å¼
    valid_formats = {"text", "json", "srt", "vtt", "verbose_json"}
    if response_format not in valid_formats:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„å“åº”æ ¼å¼: {response_format}, æ”¯æŒ: {valid_formats}"
        )
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if file.content_type:
        allowed_types = {
            "audio/wav", "audio/wave", "audio/x-wav",
            "audio/flac", "audio/x-flac",
            "audio/mpeg", "audio/mp3",
            "audio/mp4", "audio/m4a", "audio/x-m4a",
            "audio/ogg", "audio/webm",
            "application/octet-stream",  # å…è®¸æœªçŸ¥ç±»å‹
        }
        # æ”¾å®½ç±»å‹æ£€æŸ¥, å…è®¸æ›´å¤šæ ¼å¼
        logger.debug(f"æ–‡ä»¶ç±»å‹: {file.content_type}")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        audio_bytes = await file.read()
        
        if len(audio_bytes) == 0:
            raise HTTPException(status_code=400, detail="ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©º")
        
        logger.info(
            f"æ”¶åˆ°è½¬å½•è¯·æ±‚ - æ–‡ä»¶: {file.filename}, "
            f"å¤§å°: {len(audio_bytes)} bytes, "
            f"è¯­è¨€: {language}, æ ¼å¼: {response_format}"
        )
        
        # è·å–è½¬å½•å¼•æ“å¹¶æ‰§è¡Œè½¬å½•
        engine = get_transcription_engine()
        result = engine.transcribe_bytes(
            audio_bytes=audio_bytes,
            filename=file.filename or "audio.wav",
            language=language,
            response_format=response_format,
            timestamps=True,
        )
        
        # æ ¹æ®æ ¼å¼è¿”å›å“åº”
        if response_format in {"text", "srt", "vtt"}:
            return PlainTextResponse(content=result, media_type="text/plain")
        else:
            return JSONResponse(content=result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è½¬å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è½¬å½•å¤±è´¥: {e}")


@app.post("/v1/audio/translations")
async def create_translation(
    file: UploadFile = File(..., description="è¦ç¿»è¯‘çš„éŸ³é¢‘æ–‡ä»¶"),
    model: str = Form(default="canary-1b-v2", description="æ¨¡å‹åç§°"),
    response_format: str = Form(default="json", description="å“åº”æ ¼å¼"),
    temperature: Optional[float] = Form(default=None, description="é‡‡æ ·æ¸©åº¦ (å…¼å®¹å‚æ•°)"),
):
    """
    éŸ³é¢‘ç¿»è¯‘ API (ç¿»è¯‘ä¸ºè‹±è¯­)
    
    å…¼å®¹ OpenAI Whisper API çš„ /v1/audio/translations ç«¯ç‚¹
    å°†ä»»æ„æ”¯æŒçš„è¯­è¨€ç¿»è¯‘ä¸ºè‹±è¯­
    
    ## è¯·æ±‚å‚æ•°
    
    - **file**: éŸ³é¢‘æ–‡ä»¶
    - **model**: æ¨¡å‹åç§° (å…¼å®¹å‚æ•°)
    - **response_format**: å“åº”æ ¼å¼ (text, json, srt, vtt, verbose_json)
    
    ## å“åº”
    
    ç¿»è¯‘åçš„è‹±è¯­æ–‡æœ¬
    """
    valid_formats = {"text", "json", "srt", "vtt", "verbose_json"}
    if response_format not in valid_formats:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„å“åº”æ ¼å¼: {response_format}"
        )
    
    try:
        audio_bytes = await file.read()
        
        if len(audio_bytes) == 0:
            raise HTTPException(status_code=400, detail="ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©º")
        
        logger.info(
            f"æ”¶åˆ°ç¿»è¯‘è¯·æ±‚ - æ–‡ä»¶: {file.filename}, "
            f"å¤§å°: {len(audio_bytes)} bytes, æ ¼å¼: {response_format}"
        )
        
        # ç¿»è¯‘ä»»åŠ¡: æºè¯­è¨€è®¾ä¸ºè‹±è¯­ (ä¼šè‡ªåŠ¨æ£€æµ‹), ç›®æ ‡è¯­è¨€è®¾ä¸ºè‹±è¯­
        engine = get_transcription_engine()
        result = engine.transcribe_bytes(
            audio_bytes=audio_bytes,
            filename=file.filename or "audio.wav",
            language="en",  # Canary ä¼šè‡ªåŠ¨æ£€æµ‹æºè¯­è¨€
            response_format=response_format,
            timestamps=True,
            target_language="en",  # ç¿»è¯‘åˆ°è‹±è¯­
        )
        
        if response_format in {"text", "srt", "vtt"}:
            return PlainTextResponse(content=result, media_type="text/plain")
        else:
            return JSONResponse(content=result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç¿»è¯‘å¤±è´¥: {e}")


# ============================================================================
# ä¸»å…¥å£
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("API_PORT", "8000"))
    
    uvicorn.run(
        "src.main:app",
        host="0.0.0.0",
        port=port,
        reload=False,
        workers=1,  # å• worker, é¿å…å¤šè¿›ç¨‹åŠ è½½æ¨¡å‹
    )
